neighborhoods_list <- neighborhoods$estate
#neighborhoods_list_space <- paste0("\\b",neighborhoods_list,"\\b")
# Clean Prepositions List ----------------------------------------------------
tier_1_prepositions_startendword <- paste0("\\b",tier_1_prepositions,"\\b")
tier_2_prepositions_startendword <- paste0("\\b",tier_2_prepositions,"\\b")
tier_3_prepositions_startendword <- paste0("\\b",tier_3_prepositions,"\\b")
# Clean Tweet ------------------------------------------------------------------
tweet <- iconv(tweet, "latin1", "ASCII", sub="")
tweet <- tweet %>%
str_to_lower %>%
str_replace_all("\\br/about\\b", "round about") %>%
str_replace_all("\\.", " ") %>%
str_replace_all("via @[a-z_,A-Z_,0-9_]*", "") %>%
str_replace_all("\\@", "at ") %>% # "@cabanas, saying crash is at cabanas"
str_replace_all("@[a-z_,A-Z_,0-9_]*", "") %>%
str_replace_all(","," , ") %>% # Add space between commas (eg, "road,allsops")
str_replace_all("\n", "") %>%
str_replace_all("~", "") %>%
str_replace_all("\\b(http|https)://t.co/[0-9,A-Z, a-z]*\\b", "") %>%
str_replace_all("\\b(http|https)://t.co/[0-9,A-Z, a-z]", "") %>%
str_replace_all("\\b(http|https)://t.co\\b", "") %>%
str_replace_all("\\b(http|https):", "") %>%
str_replace_all("~more*", "") %>%
str_replace_all("(RT|rt) @[a-z,A-Z,0-9, _]*:", "") %>%
str_replace_all("^[0-9][0-9]\\:[0-9][0-9]", "") %>%
str_replace_all("[[:punct:]]", "") %>%
str_replace_all("\\bamp\\b", "and") %>%
# Replace words likely to trigger false positive
# Buses that include a landmark (ie, bus that primarily goes to that area)
# Could generalize: if "bus" after landmark, don't use.
str_replace_all("\\bgithurai bus\\b", "blankword blankword") %>%
str_replace_all("\\bgithurai matatu\\b", "blankword blankword") %>%
str_replace_all("\\bgithurai 45 bus\\b", "blankword blankword blankword") %>%
str_replace_all("\\bgithurai 45 matatu\\b", "blankword blankword blankword") %>%
str_replace_all("\\bcity hoppa bus\\b", "blankword blankword blankword") %>%
str_replace_all("\\bhoppa bus\\b", "blankword blankword") %>%
str_replace_all("\\brongai bus\\b", "blankword blankword") %>%
str_replace_all("\\brongai matatu\\b", "blankword blankword") %>%
str_replace_all("\\brongai matatus\\b", "blankword blankword") %>%
str_replace_all("\\bmachakos bus\\b", "blankword blankword") %>%
str_replace_all("\\bmachakos minibus\\b", "blankword blankword") %>%
str_replace_all("\\bmachakos matatu\\b", "blankword blankword") %>%
str_squish
# Locations in Tweet -----------------------------------------------------------
landmark_match <- phrase_in_sentence_exact(tweet, landmark_list)
road_match <- phrase_in_sentence_exact(tweet, roads_list)
neighborhood_match <- phrase_in_sentence_exact(tweet, neighborhoods_list)
if(fuzzy_match_landmark == TRUE){
landmark_match_fuzzy <- lapply(1:length(fuzzy_match_landmark.min.word.length), function(i){
landmark_match_fuzzy_i <- phrase_in_sentence_fuzzy(tweet,
landmark_list,
fuzzy_match_landmark.min.word.length[i],
fuzzy_match_landmark.dist[i],
fuzzy_match_ngram_max,
first_letters_same,
last_letters_same)
return(landmark_match_fuzzy_i)
}) %>%
bind_rows %>%
unique
road_match_fuzzy <- lapply(1:length(fuzzy_match_landmark.min.word.length), function(i){
road_match_fuzzy_i <- phrase_in_sentence_fuzzy(tweet,
roads_list,
fuzzy_match_landmark.min.word.length[i],
fuzzy_match_landmark.dist[i],
fuzzy_match_ngram_max,
first_letters_same,
last_letters_same)
return(road_match_fuzzy_i)
}) %>%
bind_rows %>%
unique
neighborhood_match_fuzzy <- lapply(1:length(fuzzy_match_landmark.min.word.length), function(i){
neighborhood_match_fuzzy_i <- phrase_in_sentence_fuzzy(tweet,
neighborhoods_list,
fuzzy_match_landmark.min.word.length[i],
fuzzy_match_landmark.dist[i],
fuzzy_match_ngram_max,
first_letters_same,
last_letters_same)
return(neighborhood_match_fuzzy_i)
}) %>%
bind_rows %>%
unique
# Remove fuzzy match if:
# (1) tweet spelling is one word and
# (2) tweet spelling is correctly spelled
if(nrow(landmark_match_fuzzy) > 0) landmark_match_fuzzy <- landmark_match_fuzzy[!((str_count(landmark_match_fuzzy$matched_words_tweet_spelling, "\\S+") %in% 1) & hunspell_check(as.character(landmark_match_fuzzy$matched_words_tweet_spelling))),]
if(nrow(road_match_fuzzy) > 0) road_match_fuzzy <- road_match_fuzzy[!((str_count(road_match_fuzzy$matched_words_tweet_spelling, "\\S+") %in% 1) & hunspell_check(as.character(road_match_fuzzy$matched_words_tweet_spelling))),]
if(nrow(neighborhood_match_fuzzy) > 0) neighborhood_match_fuzzy <- neighborhood_match_fuzzy[!((str_count(neighborhood_match_fuzzy$matched_words_tweet_spelling, "\\S+") %in% 1) & hunspell_check(as.character(neighborhood_match_fuzzy$matched_words_tweet_spelling))),]
# Add fuzzy match to full match list
landmark_match <- bind_rows(landmark_match, landmark_match_fuzzy) %>%
distinct(matched_words_correct_spelling, .keep_all = TRUE)
road_match <- bind_rows(road_match, road_match_fuzzy) %>%
distinct(matched_words_correct_spelling, .keep_all = TRUE)
neighborhood_match <- bind_rows(neighborhood_match, neighborhood_match_fuzzy) %>%
distinct(matched_words_correct_spelling, .keep_all = TRUE)
}
if(nrow(landmark_match) > 0) landmark_match$location_type <- "landmark"
if(nrow(road_match) > 0) road_match$location_type <- "road"
if(nrow(neighborhood_match) > 0) neighborhood_match$location_type <- "neighborhood"
locations_in_tweet <- bind_rows(landmark_match, road_match, neighborhood_match)
# Choosing which landmarks to use --------------------------------------------
df_out <- data.frame(matrix(nrow=1,ncol=0))
locations_in_tweet
# Locations of Words in Tweet --------------------------------------------------
#### Locations (landmark, roads, neighborhood)
word_locations <- lapply(as.character(locations_in_tweet$matched_words_tweet_spelling), phrase_locate, tweet) %>% bind_rows
locations_in_tweet <- merge(locations_in_tweet, word_locations, by.x="matched_words_tweet_spelling", by.y="word")
#### Other word types
crash_word_locations <- lapply(crash_words, phrase_locate, tweet) %>% bind_rows
preposition_word_locations <- lapply(prepositions_list, phrase_locate, tweet) %>% bind_rows
locations_in_tweet_original <- locations_in_tweet
landmark_match_general <- merge(landmark_match, landmark_gazetteer, by.x="matched_words_correct_spelling", by.y="name", all.x=T, all.y=F)
# If there are any general landmarks
if("general" %in% landmark_match_general$general_specific){
landmark_match_general <- landmark_match_general[landmark_match_general$general_specific %in% "general",]
# If there are roads
if(nrow(road_match) > 0){
# Add distance to road to general landmarks
coordinates(landmark_match_general) <- ~lon+lat
crs(landmark_match_general) <- CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")
roads_in_tweet <- roads[roads$name %in% road_match$matched_words_correct_spelling,]
roads_in_tweet$id <- 1
roads_in_tweet <- raster::aggregate(roads_in_tweet, by="id")
landmark_match_general$distance_to_road <- as.numeric(gDistance(landmark_match_general, roads_in_tweet, byid = T)) * 111.12
# (1) List of general landmarks far from a road; (2) remove these
landmark_match_general <- landmark_match_general[landmark_match_general$distance_to_road >= 0.5,]
landmark_match <- landmark_match[!(landmark_match$matched_words_tweet_spelling %in% landmark_match_general$matched_words_tweet_spelling),]
# If there are no roads, remove general landmarks
} else{
landmark_gazetteer <- landmark_gazetteer[!(landmark_gazetteer$general_specific %in% "general"),]
landmark_match_temp <- landmark_match[landmark_match$matched_words_correct_spelling %in% landmark_gazetteer$name,]
if(nrow(landmark_match_temp) > 0){
landmark_match <- landmark_match_temp
locations_in_tweet <- locations_in_tweet[(locations_in_tweet$matched_words_correct_spelling %in% landmark_gazetteer$name) |
!(locations_in_tweet$location_type %in% "landmark"),]
}
#landmark_match <- landmark_match[!(landmark_match$matched_words_tweet_spelling %in% landmark_match_general$matched_words_tweet_spelling),]
}
}
# Landmark intersects with road, choose road -------------------------------
locations_in_tweet <- locations_in_tweet[!(locations_in_tweet$word_loc_min %in% c(Inf,-Inf)),]
locations_in_tweet <- locations_in_tweet[!(locations_in_tweet$word_loc_max %in% c(Inf,-Inf)),]
# If road name intersects with landmark name, remove landmark
# airtel msa rd: landmark: "airtel mesa", road: "msa rd"
if( (TRUE %in% (locations_in_tweet$location_type %in% "landmark")) & (TRUE %in% (locations_in_tweet$location_type %in% "road")) ){
# Road locations
locations_in_tweet_roads <- locations_in_tweet[locations_in_tweet$location_type %in% "road",]
road_locations <- lapply(1:nrow(locations_in_tweet_roads), function(i){
road_locs <- locations_in_tweet_roads$word_loc_min[i]:locations_in_tweet_roads$word_loc_max[i]
return(road_locs)
}) %>% unlist
locations_keep <- lapply(1:nrow(locations_in_tweet), function(i){
keep <- TRUE
if(locations_in_tweet$location_type[i] %in% "landmark"){
if(TRUE %in% (locations_in_tweet$word_loc_min[i]:locations_in_tweet$word_loc_max[i] %in% road_locations)){
keep <- FALSE
}
}
return(keep)
}) %>% unlist
locations_in_tweet <- locations_in_tweet[locations_keep,] %>% unique
}
# Phase within Phrase ------------------------------------------------------
# If phrase within another phrase, choose longer one (pick "garden city mall" over "garden city").
# If phrases are same word length, keep both
locations_remove <- lapply(1:nrow(locations_in_tweet), function(i){
phrase_in_longer_phrase <- ((locations_in_tweet[i,]$word_loc_min >= locations_in_tweet[-i,]$word_loc_min) &
(locations_in_tweet[i,]$word_loc_max <= locations_in_tweet[-i,]$word_loc_max))
same_start_end <- ((locations_in_tweet[i,]$word_loc_min == locations_in_tweet[-i,]$word_loc_min) &
(locations_in_tweet[i,]$word_loc_max == locations_in_tweet[-i,]$word_loc_max))
phrase_in_longer_phrase[same_start_end] <- FALSE
return(TRUE %in% phrase_in_longer_phrase)
}) %>% unlist
locations_in_tweet <- locations_in_tweet[!locations_remove,] %>% unique
locations_in_tweet
roads[roads$name %in% "globe roundabout",]
roads[roads$name %in% "globe roundabout",] %>% plot
roads[roads$name %in% "globe roundabout",] %>% gLenth()
library(rgoes)
library(rgeos)
roads[roads$name %in% "globe roundabout",] %>% gLenth()
roads[roads$name %in% "globe roundabout",] %>% gLength()
0.005222585*111.12
# Test Geolocation Algorithm
# TODO: In classification, add "how_got_type" for how found -- so can see which one
# is more accurate; subset; etc.
# Spellign: severe --> seven? If word is already spelled correctly (eg, "called"), don't consider. Hmmmm might not work
# CLUSTER TRUTH TWEETS -- HOW MANY CRASHES ACTUALLY MISS
# Setup ------------------------------------------------------------------------
if(Sys.info()["user"] == "WB521633") project_file_path <- "C:/Users/wb521633/Dropbox/World Bank/IEs/CrashMap-Nairobi"
if(Sys.info()["user"] == "robmarty") project_file_path <- "~/Dropbox/World Bank/IEs/CrashMap-Nairobi"
source(file.path(project_file_path, "Twitter Geocode Algorithm", "code", "04_algorithm", "crashmap_algorithm.R"))
library(pbmcapply)
INCORRECT_TWEETS <- FALSE
tweet <- "08:17 @danielnjorogeh their is a minor accident at spring valley via @willie50996679"
tweet <- "accident at githurai overpass please use service lane and rejoin highway after githurai stage"
tweet <- "05:15 accident at 411 kitengela namanga rd. nduthi and toyota wish via @lkiage"
tweet <- "accident at gardent city sf cd cid"
tweet <- "accident at green park estate on mombasa road"
tweet <- "accident near canadian embassy along limuru rd causing a heavy traffic snarl up... both in and out bound locked in traffic. no traffic police yet"
tweet <- "accident past yaya center near garden city"
tweet <- "accident past yaya center near garden city on thika rd"
tweet <- "08:06 multiple accidents on waiyaki way..at 87 and uthiru. via @8isaac5"
tweet <- "there is an accident words words at garden city near safari park on thika rd"
tweet <- "20:40 20:39 accident on mombasa rd. next to airtel. via @ochiengbonn\r\n just via @jacfar4661"
tweet <- "20:36 mombasa road parking lot... at dtb accident 1/2km before that. https://t.co/kyh1m5yanx via @eunicenyandat"
tweet <- "a pedestrian has been knocked down at airtel msa rd. thats what is slowing traffic from gm"
tweet <- "10:27 accident on kiambu rd muthaiga after cid headquarters towards town.. recovery going on https://t.co/cprdjkfkm7 via @sal_gooh"
tweet <- "93 07:59 lorry overturn opposite alpha center apo cabanas causing jam but police on scene #trafficupdate via @gabu_don"
tweet <- "11:24 two accidents near mai mahiu town. traffic police on site @ntsa_kenya via @kenmoturi"
tweet <- "accident at blue post"
tweet <- "accident on mombasa rd just after belle vue out bound truck carrying glass cargo laying invite side and broken glass on road"
tweet <- "a certain mheshimiwa car has been hit @ the back under pangani footbridge. ...with sirens on....it's a scenery already."
tweet <- "at drive-inn (thika road). a driver of an exhauster truck loses control checking the guardrails. no serious injuries to pe sons bt to the vehicle itself. @kenhakenya https://t.co/j4raxybmsb"
tweet <- "20:36 mombasa road parking lot... at dtb accident 1/2km before that. https://t.co/kyh1m5yanx via @eunicenyandat"
tweet <- "20:03 accident on thika road gsu depression tuvumiliane cops on it via @njugunastevens"
tweet <- "10:36 minor accident at the kangemi stage after the bridge heading to town via @zollynash"
tweet <- "accident at globe roundabout"
fuzzy_match_landmark <- TRUE
fuzzy_match_landmark.min.word.length <- c(5,11) # minimum word length for fuzzy match
fuzzy_match_landmark.dist <- c(1,2) # maximum levenstein distance to use
fuzzy_match_ngram_max <- 3
prepositions_list <- c("near", "at")
crash_words <- c("accidents", "accident", "crash", "overturn", "collision", "wreck") # hit?
junction_words <- c("intersection", "junction")
first_letters_same <- TRUE
last_letters_same <- TRUE # !!!!!!!! fails for roysambo/u. Maybe: if 1 letter off, only first letter needs to be same. But be more restrictive with 2?
import_files <- FALSE
tier_1_prepositions <- c("at", "next to","around", "just after", "opposite","opp", "apa", "hapa","happened at","just before","at the","outside")
tier_2_prepositions <- c("near", "after", "toward","along", "towards")
tier_3_prepositions <- c("past","from")
# Import
landmark_gazetteer_orig <- readRDS(file.path(project_file_path, "Twitter Geocode Algorithm", "data", "finaldata", "gazetteers_augmented", "gazetteer_aug.Rds"))
roads <- readRDS(file.path(project_file_path, "Twitter Geocode Algorithm", "data", "finaldata", "roads_augmented", "osm_roads_aug.Rds"))
neighborhoods <- readRDS(file.path(project_file_path, "Twitter Geocode Algorithm", "data", "finaldata", "nairobi_estates", "nairobi_estates.Rds"))
locate_crash("accident at globe roundabout")
locate_crash("accident at globe round about")
# Test Geolocation Algorithm
# TODO: In classification, add "how_got_type" for how found -- so can see which one
# is more accurate; subset; etc.
# Spellign: severe --> seven? If word is already spelled correctly (eg, "called"), don't consider. Hmmmm might not work
# CLUSTER TRUTH TWEETS -- HOW MANY CRASHES ACTUALLY MISS
# Setup ------------------------------------------------------------------------
if(Sys.info()["user"] == "WB521633") project_file_path <- "C:/Users/wb521633/Dropbox/World Bank/IEs/CrashMap-Nairobi"
if(Sys.info()["user"] == "robmarty") project_file_path <- "~/Dropbox/World Bank/IEs/CrashMap-Nairobi"
source(file.path(project_file_path, "Twitter Geocode Algorithm", "code", "04_algorithm", "crashmap_algorithm.R"))
library(pbmcapply)
INCORRECT_TWEETS <- FALSE
tweet <- "08:17 @danielnjorogeh their is a minor accident at spring valley via @willie50996679"
tweet <- "accident at githurai overpass please use service lane and rejoin highway after githurai stage"
tweet <- "05:15 accident at 411 kitengela namanga rd. nduthi and toyota wish via @lkiage"
tweet <- "accident at gardent city sf cd cid"
tweet <- "accident at green park estate on mombasa road"
tweet <- "accident near canadian embassy along limuru rd causing a heavy traffic snarl up... both in and out bound locked in traffic. no traffic police yet"
tweet <- "accident past yaya center near garden city"
tweet <- "accident past yaya center near garden city on thika rd"
tweet <- "08:06 multiple accidents on waiyaki way..at 87 and uthiru. via @8isaac5"
tweet <- "there is an accident words words at garden city near safari park on thika rd"
tweet <- "20:40 20:39 accident on mombasa rd. next to airtel. via @ochiengbonn\r\n just via @jacfar4661"
tweet <- "20:36 mombasa road parking lot... at dtb accident 1/2km before that. https://t.co/kyh1m5yanx via @eunicenyandat"
tweet <- "a pedestrian has been knocked down at airtel msa rd. thats what is slowing traffic from gm"
tweet <- "10:27 accident on kiambu rd muthaiga after cid headquarters towards town.. recovery going on https://t.co/cprdjkfkm7 via @sal_gooh"
tweet <- "93 07:59 lorry overturn opposite alpha center apo cabanas causing jam but police on scene #trafficupdate via @gabu_don"
tweet <- "11:24 two accidents near mai mahiu town. traffic police on site @ntsa_kenya via @kenmoturi"
tweet <- "accident at blue post"
tweet <- "accident on mombasa rd just after belle vue out bound truck carrying glass cargo laying invite side and broken glass on road"
tweet <- "a certain mheshimiwa car has been hit @ the back under pangani footbridge. ...with sirens on....it's a scenery already."
tweet <- "at drive-inn (thika road). a driver of an exhauster truck loses control checking the guardrails. no serious injuries to pe sons bt to the vehicle itself. @kenhakenya https://t.co/j4raxybmsb"
tweet <- "20:36 mombasa road parking lot... at dtb accident 1/2km before that. https://t.co/kyh1m5yanx via @eunicenyandat"
tweet <- "20:03 accident on thika road gsu depression tuvumiliane cops on it via @njugunastevens"
tweet <- "10:36 minor accident at the kangemi stage after the bridge heading to town via @zollynash"
tweet <- "accident at globe roundabout"
fuzzy_match_landmark <- TRUE
fuzzy_match_landmark.min.word.length <- c(5,11) # minimum word length for fuzzy match
fuzzy_match_landmark.dist <- c(1,2) # maximum levenstein distance to use
fuzzy_match_ngram_max <- 3
prepositions_list <- c("near", "at")
crash_words <- c("accidents", "accident", "crash", "overturn", "collision", "wreck") # hit?
junction_words <- c("intersection", "junction")
first_letters_same <- TRUE
last_letters_same <- TRUE # !!!!!!!! fails for roysambo/u. Maybe: if 1 letter off, only first letter needs to be same. But be more restrictive with 2?
import_files <- FALSE
tier_1_prepositions <- c("at", "next to","around", "just after", "opposite","opp", "apa", "hapa","happened at","just before","at the","outside")
tier_2_prepositions <- c("near", "after", "toward","along", "towards")
tier_3_prepositions <- c("past","from")
# Import
landmark_gazetteer_orig <- readRDS(file.path(project_file_path, "Twitter Geocode Algorithm", "data", "finaldata", "gazetteers_augmented", "gazetteer_aug.Rds"))
roads <- readRDS(file.path(project_file_path, "Twitter Geocode Algorithm", "data", "finaldata", "roads_augmented", "osm_roads_aug.Rds"))
neighborhoods <- readRDS(file.path(project_file_path, "Twitter Geocode Algorithm", "data", "finaldata", "nairobi_estates", "nairobi_estates.Rds"))
# Load Data --------------------------------------------------------------------
if(INCORRECT_TWEETS){
truth_data <- readRDS(file.path(project_file_path, "Data", "FinalData", "Twitter", "Truth Data", "twitter_truth_data_algincorrect.Rds"))
output_name <- "twitter_truth_data_crashmapalgorithm_algincorrect"
} else{
truth_data <- readRDS(file.path(project_file_path, "Data", "FinalData", "Twitter", "Truth Data", "twitter_truth_data.Rds"))
truth_data <- truth_data[truth_data$accident_truth %in% TRUE,]
truth_data <- truth_data[!is.na(truth_data$longitude_truth),]
output_name <- "twitter_truth_data_crashmapalgorithm"
}
n_begin <- 1
n_end <- nrow(truth_data)
#n_end <- 150
nrow(n_end)
# Implement Algorithm ----------------------------------------------------------
#algorithm_output_list <- pbmclapply(truth_data$tweet[n_begin:n_end], locate_crash, mc.cores=2)
algorithm_output_list <- lapply(truth_data$tweet[n_begin:n_end], locate_crash)
algorithm_output <- algorithm_output_list %>% bind_rows
truth_data_with_algorithm_output <- cbind(algorithm_output, truth_data[n_begin:n_end,])
# Export -----------------------------------------------------------------------
write.csv(truth_data_with_algorithm_output,
file.path(project_file_path, "Data", "FinalData", "Twitter", "Truth Data", "Truth Datasets with Algorithm Output",
paste0(output_name,".csv")),
row.names=F)
saveRDS(truth_data_with_algorithm_output,
file.path(project_file_path, "Data", "FinalData", "Twitter", "Truth Data", "Truth Datasets with Algorithm Output",
paste0(output_name,".Rds")))
# Test Geolocation Algorithm
# TODO
# if mention road, take road out of tweet -- so none of words can be considered a landmark
# EXISTS ON GOOGLE BUT NOT IN GAZETTER
# alpha center
# homeland
# Setup ------------------------------------------------------------------------
if(Sys.info()["user"] == "WB521633") project_file_path <- "C:/Users/wb521633/Dropbox/World Bank/IEs/CrashMap-Nairobi"
if(Sys.info()["user"] == "robmarty") project_file_path <- "~/Dropbox/World Bank/IEs/CrashMap-Nairobi"
source(file.path(project_file_path, "Twitter Geocode Algorithm", "code", "04_algorithm", "crashmap_algorithm.R"))
INCORRECT_TWEETS <- FALSE
# Load Data --------------------------------------------------------------------
if(INCORRECT_TWEETS){
truth_data_alg <- readRDS(file.path(project_file_path, "Data", "FinalData", "Twitter", "Truth Data","Truth Datasets with Algorithm Output", "twitter_truth_data_crashmapalgorithm_algincorrect.Rds"))
} else{
truth_data_alg <- readRDS(file.path(project_file_path, "Data", "FinalData", "Twitter", "Truth Data","Truth Datasets with Algorithm Output", "twitter_truth_data_crashmapalgorithm.Rds"))
}
truth_data_alg$alg_truth_coord_distance <-
sqrt((truth_data_alg$lon - truth_data_alg$longitude_truth)^2 +
(truth_data_alg$lat - truth_data_alg$latitude_truth)^2) * 111.12
#### Clean Types
truth_data_alg$type <- lapply(1:nrow(truth_data_alg), function(i){
type_shortened <- strsplit(truth_data_alg$type[i], ",")[[1]] %>% unique %>% paste(collapse=",")
return(type_shortened)
}) %>% unlist
# Distance Closest Landmark ----------------------------------------------------
landmark_gazetteer_aug <- readRDS(file.path(project_file_path, "Twitter Geocode Algorithm", "data", "finaldata", "gazetteers_augmented", "gazetteer_aug.Rds"))
all_landmarks_found <- strsplit(truth_data_alg$landmarks_all_correct_spelling, ",") %>% unlist %>% unique
landmark_gazetteer_aug_subset <- landmark_gazetteer_aug[landmark_gazetteer_aug$name %in% all_landmarks_found,]
calc_distance_closest_landmark <- function(i){
landmarks_found <- strsplit(truth_data_alg$landmarks_all_correct_spelling[i], ",")[[1]] %>% unique
landmark_gazetteer_aug_i <- landmark_gazetteer_aug_subset[landmark_gazetteer_aug_subset$name %in% landmarks_found,]
distance_closested_landmark <- min(sqrt((landmark_gazetteer_aug_i$lat - truth_data_alg$lat[i])^2 + (landmark_gazetteer_aug_i$lon - truth_data_alg$lon[i])^2))*111.12
return(distance_closested_landmark)
}
truth_data_alg$dist_closest_landmark <- lapply(1:nrow(truth_data_alg), calc_distance_closest_landmark) %>% unlist
# Quick stats of performance ---------------------------------------------------
N_tweets <- nrow(truth_data_alg)
truth_data_alg <- truth_data_alg[!grepl("location_not_near_mentioned_roads_so_make_NA", truth_data_alg$how_determined_landmark),]
#truth_data_alg <- truth_data_alg[!is.na(truth_data_alg$roads_all_correct_spelling),]
#truth_data_alg <- truth_data_alg[!grepl("multiple_landmarks_choose_closest_crashword", truth_data_alg$how_determined_landmark),]
#truth_data_alg <- truth_data_alg[!grepl("landmark_ambiguous_patternmultiple_landmarks_choose_closest_crashword", truth_data_alg$how_determined_landmark),]
#truth_data_alg$matched_words_correct_spelling_unique <- truth_data_alg$matched_words_correct_spelling %>% lapply(function(words) strsplit(words, split=",")[[1]] %>% unique %>% paste(collapse=",")) %>% unlist
#truth_data_alg$matched_words_correct_spelling_unique_spelledcorrect <- hunspell_check(truth_data_alg$matched_words_correct_spelling_unique)
#truth_data_alg <- truth_data_alg[truth_data_alg$matched_words_correct_spelling_unique_spelledcorrect == FALSE,]
#truth_data_alg <- truth_data_alg[truth_data_alg$matched_words_correct_spelling == truth_data_alg$matched_words_tweet_spelling,]
table(truth_data_alg$alg_truth_coord_distance < 1)
# RECALL
# Test Geolocation Algorithm
# TODO
# if mention road, take road out of tweet -- so none of words can be considered a landmark
# EXISTS ON GOOGLE BUT NOT IN GAZETTER
# alpha center
# homeland
# Setup ------------------------------------------------------------------------
if(Sys.info()["user"] == "WB521633") project_file_path <- "C:/Users/wb521633/Dropbox/World Bank/IEs/CrashMap-Nairobi"
if(Sys.info()["user"] == "robmarty") project_file_path <- "~/Dropbox/World Bank/IEs/CrashMap-Nairobi"
source(file.path(project_file_path, "Twitter Geocode Algorithm", "code", "04_algorithm", "crashmap_algorithm.R"))
INCORRECT_TWEETS <- FALSE
# Load Data --------------------------------------------------------------------
if(INCORRECT_TWEETS){
truth_data_alg <- readRDS(file.path(project_file_path, "Data", "FinalData", "Twitter", "Truth Data","Truth Datasets with Algorithm Output", "twitter_truth_data_crashmapalgorithm_algincorrect.Rds"))
} else{
truth_data_alg <- readRDS(file.path(project_file_path, "Data", "FinalData", "Twitter", "Truth Data","Truth Datasets with Algorithm Output", "twitter_truth_data_crashmapalgorithm.Rds"))
}
truth_data_alg$alg_truth_coord_distance <-
sqrt((truth_data_alg$lon - truth_data_alg$longitude_truth)^2 +
(truth_data_alg$lat - truth_data_alg$latitude_truth)^2) * 111.12
#### Clean Types
truth_data_alg$type <- lapply(1:nrow(truth_data_alg), function(i){
type_shortened <- strsplit(truth_data_alg$type[i], ",")[[1]] %>% unique %>% paste(collapse=",")
return(type_shortened)
}) %>% unlist
# Distance Closest Landmark ----------------------------------------------------
landmark_gazetteer_aug <- readRDS(file.path(project_file_path, "Twitter Geocode Algorithm", "data", "finaldata", "gazetteers_augmented", "gazetteer_aug.Rds"))
all_landmarks_found <- strsplit(truth_data_alg$landmarks_all_correct_spelling, ",") %>% unlist %>% unique
landmark_gazetteer_aug_subset <- landmark_gazetteer_aug[landmark_gazetteer_aug$name %in% all_landmarks_found,]
calc_distance_closest_landmark <- function(i){
landmarks_found <- strsplit(truth_data_alg$landmarks_all_correct_spelling[i], ",")[[1]] %>% unique
landmark_gazetteer_aug_i <- landmark_gazetteer_aug_subset[landmark_gazetteer_aug_subset$name %in% landmarks_found,]
distance_closested_landmark <- min(sqrt((landmark_gazetteer_aug_i$lat - truth_data_alg$lat[i])^2 + (landmark_gazetteer_aug_i$lon - truth_data_alg$lon[i])^2))*111.12
return(distance_closested_landmark)
}
truth_data_alg$dist_closest_landmark <- lapply(1:nrow(truth_data_alg), calc_distance_closest_landmark) %>% unlist
# Quick stats of performance ---------------------------------------------------
N_tweets <- nrow(truth_data_alg)
#truth_data_alg <- truth_data_alg[!grepl("location_not_near_mentioned_roads_so_make_NA", truth_data_alg$how_determined_landmark),]
#truth_data_alg <- truth_data_alg[!is.na(truth_data_alg$roads_all_correct_spelling),]
#truth_data_alg <- truth_data_alg[!grepl("multiple_landmarks_choose_closest_crashword", truth_data_alg$how_determined_landmark),]
#truth_data_alg <- truth_data_alg[!grepl("landmark_ambiguous_patternmultiple_landmarks_choose_closest_crashword", truth_data_alg$how_determined_landmark),]
#truth_data_alg$matched_words_correct_spelling_unique <- truth_data_alg$matched_words_correct_spelling %>% lapply(function(words) strsplit(words, split=",")[[1]] %>% unique %>% paste(collapse=",")) %>% unlist
#truth_data_alg$matched_words_correct_spelling_unique_spelledcorrect <- hunspell_check(truth_data_alg$matched_words_correct_spelling_unique)
#truth_data_alg <- truth_data_alg[truth_data_alg$matched_words_correct_spelling_unique_spelledcorrect == FALSE,]
#truth_data_alg <- truth_data_alg[truth_data_alg$matched_words_correct_spelling == truth_data_alg$matched_words_tweet_spelling,]
table(truth_data_alg$alg_truth_coord_distance < 1)
3062(3062+971)
3062/(3062+971)
# RECALL
sum(truth_data_alg$alg_truth_coord_distance < 1, na.rm=T) / N_tweets
# PRECISION
mean(truth_data_alg$alg_truth_coord_distance < 1, na.rm=T)
mean(truth_data_alg$dist_closest_landmark < 1, na.rm=T) # metric to compare to LNEx
# Test Geolocation Algorithm
# TODO
# if mention road, take road out of tweet -- so none of words can be considered a landmark
# EXISTS ON GOOGLE BUT NOT IN GAZETTER
# alpha center
# homeland
# Setup ------------------------------------------------------------------------
if(Sys.info()["user"] == "WB521633") project_file_path <- "C:/Users/wb521633/Dropbox/World Bank/IEs/CrashMap-Nairobi"
if(Sys.info()["user"] == "robmarty") project_file_path <- "~/Dropbox/World Bank/IEs/CrashMap-Nairobi"
source(file.path(project_file_path, "Twitter Geocode Algorithm", "code", "04_algorithm", "crashmap_algorithm.R"))
INCORRECT_TWEETS <- FALSE
# Load Data --------------------------------------------------------------------
if(INCORRECT_TWEETS){
truth_data_alg <- readRDS(file.path(project_file_path, "Data", "FinalData", "Twitter", "Truth Data","Truth Datasets with Algorithm Output", "twitter_truth_data_crashmapalgorithm_algincorrect.Rds"))
} else{
truth_data_alg <- readRDS(file.path(project_file_path, "Data", "FinalData", "Twitter", "Truth Data","Truth Datasets with Algorithm Output", "twitter_truth_data_crashmapalgorithm.Rds"))
}
truth_data_alg$alg_truth_coord_distance <-
sqrt((truth_data_alg$lon - truth_data_alg$longitude_truth)^2 +
(truth_data_alg$lat - truth_data_alg$latitude_truth)^2) * 111.12
#### Clean Types
truth_data_alg$type <- lapply(1:nrow(truth_data_alg), function(i){
type_shortened <- strsplit(truth_data_alg$type[i], ",")[[1]] %>% unique %>% paste(collapse=",")
return(type_shortened)
}) %>% unlist
# Distance Closest Landmark ----------------------------------------------------
landmark_gazetteer_aug <- readRDS(file.path(project_file_path, "Twitter Geocode Algorithm", "data", "finaldata", "gazetteers_augmented", "gazetteer_aug.Rds"))
all_landmarks_found <- strsplit(truth_data_alg$landmarks_all_correct_spelling, ",") %>% unlist %>% unique
landmark_gazetteer_aug_subset <- landmark_gazetteer_aug[landmark_gazetteer_aug$name %in% all_landmarks_found,]
calc_distance_closest_landmark <- function(i){
landmarks_found <- strsplit(truth_data_alg$landmarks_all_correct_spelling[i], ",")[[1]] %>% unique
landmark_gazetteer_aug_i <- landmark_gazetteer_aug_subset[landmark_gazetteer_aug_subset$name %in% landmarks_found,]
distance_closested_landmark <- min(sqrt((landmark_gazetteer_aug_i$lat - truth_data_alg$lat[i])^2 + (landmark_gazetteer_aug_i$lon - truth_data_alg$lon[i])^2))*111.12
return(distance_closested_landmark)
}
truth_data_alg$dist_closest_landmark <- lapply(1:nrow(truth_data_alg), calc_distance_closest_landmark) %>% unlist
# Quick stats of performance ---------------------------------------------------
N_tweets <- nrow(truth_data_alg)
truth_data_alg <- truth_data_alg[!grepl("location_not_near_mentioned_roads_so_make_NA", truth_data_alg$how_determined_landmark),]
#truth_data_alg <- truth_data_alg[!is.na(truth_data_alg$roads_all_correct_spelling),]
#truth_data_alg <- truth_data_alg[!grepl("multiple_landmarks_choose_closest_crashword", truth_data_alg$how_determined_landmark),]
#truth_data_alg <- truth_data_alg[!grepl("landmark_ambiguous_patternmultiple_landmarks_choose_closest_crashword", truth_data_alg$how_determined_landmark),]
#truth_data_alg$matched_words_correct_spelling_unique <- truth_data_alg$matched_words_correct_spelling %>% lapply(function(words) strsplit(words, split=",")[[1]] %>% unique %>% paste(collapse=",")) %>% unlist
#truth_data_alg$matched_words_correct_spelling_unique_spelledcorrect <- hunspell_check(truth_data_alg$matched_words_correct_spelling_unique)
#truth_data_alg <- truth_data_alg[truth_data_alg$matched_words_correct_spelling_unique_spelledcorrect == FALSE,]
#truth_data_alg <- truth_data_alg[truth_data_alg$matched_words_correct_spelling == truth_data_alg$matched_words_tweet_spelling,]
table(truth_data_alg$alg_truth_coord_distance < 1)
# RECALL
sum(truth_data_alg$alg_truth_coord_distance < 1, na.rm=T) / N_tweets
# PRECISION
mean(truth_data_alg$alg_truth_coord_distance < 1, na.rm=T)
mean(truth_data_alg$dist_closest_landmark < 1, na.rm=T) # metric to compare to LNEx
mean(truth_data_alg$dist_closest_landmark < 1 | truth_data_alg$alg_truth_coord_distance < 1, na.rm=T) # metric to compare to LNEx
results_df_i$iso
# Setup ------------------------------------------------------------------------
if(Sys.info()[["user"]] == "WB521633") project_file_path <- "C:/Users/wb521633/Dropbox/World Bank/IEs/CrashMap-Nairobi"
if(Sys.info()[["user"]] == "robmarty") project_file_path <- "~/Dropbox/World Bank/IEs/CrashMap-Nairobi"
library(lubridate)
library(tidyverse)
LATEST_FILE <- "crash_survey_pilot_2019-05-10.csv"
# Process Data -----------------------------------------------------------------
crash_reports <- read_csv(file.path(project_file_path, "Data", "RawData", "Sendy", "Crash Reports Accounting", "full_data_downloads", LATEST_FILE))
crash_reports_est <- crash_reports %>%
filter(!duplicated(.)) %>%
mutate(date_sub = parse_date_time(SubmissionDate, orders = "b d, Y I:M:S p", tz = "America/New_York")) %>%
mutate(date_start = parse_date_time(starttime, orders = "b d, Y I:M:S p", tz = "America/New_York")) %>%
mutate(end_date = parse_date_time(endtime, orders = "b d, Y I:M:S p", tz = "America/New_York")) %>%
mutate(date_notime = as.Date(date_start, "%Y-%m-%d", tz = "America/New_York")) %>%
filter(date_start >= ymd_hms("2018-10-05 00:00:00", tz = "America/New_York")) %>%
mutate(rider_name = case_when(!is.na(name_label) ~ str_to_lower(name_label),
is.na(name_label) ~ str_to_lower(name_other)))
# filter crash reports since last check
crash_reports_previous <- read_csv(sort(list.files(file.path(project_file_path, "Data", "RawData", "Sendy", "Crash Reports Accounting", "latest"),  full.names=T), decreasing=T)[1])
# get id of latest crash report in previous data
previous_latest_id <- crash_reports_previous %>%
filter(date_sub == max(date_sub)) %>%
pull(KEY)
# sort current data by submitted date and then filter anything after the latest id
crash_reports_latest <- crash_reports_est %>%
arrange(date_sub) %>%
mutate(latest_key_row = which(KEY == previous_latest_id)) %>%
filter(row_number() > latest_key_row) %>%
dplyr::select(-latest_key_row)
crash_reports_latest %>%
group_by(rider_name) %>%
count() %>%
arrange(desc(n))
crash_reports_latest %>%
group_by(rider_name) %>%
count() %>%
mutate(pay = n*250) %>%
arrange(desc(n))
